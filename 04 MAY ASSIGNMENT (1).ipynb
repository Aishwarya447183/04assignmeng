{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd0b67-b03b-43ab-837c-5545659904ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q1.\n",
    "\n",
    "A time series is a sequence of data points collected or recorded in a sequential order over time. It represents the values of a variable or multiple variables at different time intervals. The data points are typically equally spaced, such as hourly, daily, monthly, or yearly measurements. Time series analysis involves studying and analyzing the patterns, trends, and characteristics of the data to make predictions or gain insights into future behavior.\n",
    "\n",
    "Time series analysis has various applications across different fields. Some common applications include:\n",
    "\n",
    "Finance and Economics: Time series analysis is extensively used in financial markets to forecast stock prices, predict market trends, and analyze economic indicators such as GDP, inflation rates, and interest rates.\n",
    "\n",
    "Weather Forecasting: Meteorologists analyze time series data to predict weather patterns, temperature variations, rainfall, and other atmospheric conditions.\n",
    "\n",
    "Sales and Demand Forecasting: Time series analysis helps businesses forecast future sales and demand patterns, enabling them to make informed decisions regarding inventory management, production planning, and resource allocation.\n",
    "\n",
    "Stock Market Analysis: Investors and traders use time series analysis techniques to analyze historical price movements and identify patterns, trends, and market signals to make investment decisions.\n",
    "\n",
    "Predictive Maintenance: Time series analysis is applied in industrial settings to monitor equipment performance, detect anomalies, and predict maintenance requirements, reducing downtime and improving operational efficiency.\n",
    "\n",
    "Energy Load Forecasting: Utilities and energy providers analyze time series data to forecast electricity demand and optimize energy generation, distribution, and pricing strategies.\n",
    "\n",
    "Health Monitoring: Time series analysis plays a role in monitoring patient vital signs, disease progression, and treatment effectiveness. It can also aid in epidemic outbreak detection and prediction.\n",
    "\n",
    "Website Traffic Analysis: Website owners use time series analysis to understand user behavior, traffic patterns, and identify peak usage times to optimize website performance and plan server capacity.\n",
    "\n",
    "These are just a few examples, and time series analysis finds applications in various other domains, wherever data is collected and recorded over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcacc9e-6139-42ae-82e0-f4c64b89dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q2.\n",
    "\n",
    "There are several common patterns that can be observed in time series data. Here are some of the key patterns and their interpretations:\n",
    "\n",
    "Trend: A trend represents the long-term movement or direction of the data over time. It indicates whether the values are generally increasing (upward trend) or decreasing (downward trend). Trend analysis helps identify underlying growth or decline in the data and can provide insights into the overall behavior of the variable.\n",
    "\n",
    "Seasonality: Seasonality refers to a regular pattern that repeats over fixed time intervals, such as daily, weekly, monthly, or yearly. It represents predictable fluctuations in the data caused by seasonal factors. Seasonality can be observed in various domains, such as sales, weather, and economic indicators. Identifying seasonality is crucial for understanding and predicting cyclic patterns.\n",
    "\n",
    "Cyclical: Cyclical patterns occur over an extended period, typically longer than seasonality, and do not have a fixed time interval. These patterns represent fluctuations that are not necessarily regular but can still exhibit a repetitive behavior. Cyclical patterns are often associated with economic or business cycles and can have a significant impact on the data.\n",
    "\n",
    "Irregular/Random: Irregular or random patterns refer to unpredictable variations in the data that cannot be explained by trends, seasonality, or cycles. They represent random fluctuations, noise, or unexpected events that can affect the data. Identifying and accounting for irregular patterns is important to avoid misleading interpretations and to focus on the underlying patterns of interest.\n",
    "\n",
    "Autocorrelation: Autocorrelation refers to the relationship between the values of a time series at different time lags. Positive autocorrelation indicates that past values influence future values in a systematic way, while negative autocorrelation suggests an inverse relationship. Autocorrelation analysis helps identify dependencies and correlations within the data, which can be useful for forecasting and understanding the data's behavior.\n",
    "\n",
    "To identify and interpret these patterns, various statistical and visual techniques can be employed:\n",
    "\n",
    "Visual inspection: Plotting the data as a line graph or a scatter plot can often reveal the presence of trends, seasonality, or other patterns visually.\n",
    "\n",
    "Moving averages: Calculating and plotting moving averages helps smooth out the noise in the data and highlight the underlying trend.\n",
    "\n",
    "Decomposition: Decomposing the time series into its trend, seasonality, and residual components using techniques like additive or multiplicative decomposition can aid in understanding and interpreting each component separately.\n",
    "\n",
    "Autocorrelation analysis: Computing autocorrelation and partial autocorrelation functions can help identify the presence of correlation and patterns in the data at different lags.\n",
    "\n",
    "Statistical models: Applying time series models such as ARIMA (Autoregressive Integrated Moving Average) or exponential smoothing methods can capture and quantify different patterns in the data.\n",
    "\n",
    "By applying these techniques and considering the context of the data, analysts can identify and interpret the patterns present in time series data, which can then inform decision-making, forecasting, and predictive modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4162fd33-c004-41e6-8282-5145e0ba53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q3.\n",
    "\n",
    "Preprocessing time series data is an essential step before applying analysis techniques. It involves transforming and cleaning the data to ensure its quality, remove noise or outliers, handle missing values, and make it suitable for analysis. Here are some common preprocessing steps for time series data:\n",
    "\n",
    "Handling Missing Values: Missing values can occur in time series data due to various reasons such as sensor failures or data collection issues. Depending on the extent of missing values, you can choose to remove the corresponding time points, interpolate the missing values using techniques like linear interpolation or spline interpolation, or use more advanced methods such as imputation algorithms specific to time series data.\n",
    "\n",
    "Removing Outliers: Outliers are extreme values that deviate significantly from the general pattern of the data. They can distort analysis results and affect the accuracy of models. Outliers can be identified using statistical techniques such as z-scores, box plots, or median absolute deviation (MAD) and can be treated by either removing them if they are erroneous or by replacing them with more representative values.\n",
    "\n",
    "Resampling and Aggregating: Time series data may be recorded at a high frequency or irregular intervals. Resampling involves converting the data to a lower frequency (e.g., from hourly to daily data) or regularizing the time intervals. Aggregating the data can also be useful, especially when dealing with large datasets, by summarizing values within a specific time window (e.g., taking the mean, sum, or maximum values).\n",
    "\n",
    "Detrending: Detrending is the process of removing the trend component from the data. It helps in analyzing the underlying patterns and residuals more accurately. Detrending methods include fitting regression models, differencing the data, or using techniques like moving averages.\n",
    "\n",
    "Normalization and Scaling: Time series data may have different scales, which can affect the performance of certain analysis techniques. Normalizing the data by scaling it between a specified range (e.g., 0 to 1) or standardizing it using z-scores can help in comparing and analyzing different variables on a consistent scale.\n",
    "\n",
    "Handling Seasonality: If seasonality is present in the data, it may need to be addressed separately. Seasonal adjustment methods such as seasonal differencing or seasonal decomposition can be applied to remove the seasonal component, making the data more suitable for further analysis.\n",
    "\n",
    "Feature Engineering: Time series data can often benefit from feature engineering, which involves creating additional variables or features that capture relevant information from the data. These features can include lagged values, moving averages, exponential smoothing, or other domain-specific transformations that help in capturing meaningful patterns.\n",
    "\n",
    "It's important to note that the specific preprocessing steps and techniques used may vary depending on the nature of the data, the analysis objectives, and the domain knowledge. It is often a combination of data exploration, statistical analysis, and domain expertise that guides the preprocessing steps for time series data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7549a-3b52-461c-a88e-a2e171e70eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q4.\n",
    "\n",
    "\n",
    "\n",
    "Time series forecasting plays a crucial role in business decision-making by providing insights and predictions about future trends, patterns, and behavior of the data. Here are some ways in which time series forecasting is used in business:\n",
    "\n",
    "Demand Forecasting: Businesses rely on accurate demand forecasts to optimize inventory management, production planning, and supply chain operations. Time series forecasting models help estimate future demand based on historical sales data, allowing businesses to make informed decisions regarding production volumes, procurement, and resource allocation.\n",
    "\n",
    "Financial Planning: Time series forecasting is valuable in financial planning and budgeting. It helps businesses predict future financial metrics such as sales revenue, cash flow, expenses, and profit. These forecasts aid in setting financial targets, evaluating investment decisions, and determining resource allocation strategies.\n",
    "\n",
    "Resource Optimization: Time series forecasting is employed to optimize resource allocation in various areas. For example, in workforce management, forecasting future staffing requirements helps businesses schedule and allocate human resources efficiently. In energy management, load forecasting helps utilities optimize energy generation, distribution, and pricing strategies.\n",
    "\n",
    "Marketing and Sales: Time series forecasting assists in marketing and sales planning by predicting customer behavior, sales volumes, and market trends. Businesses can leverage these forecasts to optimize marketing campaigns, plan promotions, and allocate resources effectively.\n",
    "\n",
    "Risk Management: Time series forecasting is used in risk management to predict and mitigate potential risks. For instance, in insurance, forecasting claim frequency and severity helps insurers estimate future liabilities and set appropriate premiums. In financial markets, time series forecasting aids in risk assessment, portfolio management, and trading strategies.\n",
    "\n",
    "Despite its benefits, time series forecasting also poses some challenges and limitations. Here are a few common ones:\n",
    "\n",
    "Noisy and Incomplete Data: Time series data can be noisy, containing random variations, outliers, and missing values. Dealing with these data quality issues can affect the accuracy of forecasts and require appropriate preprocessing and imputation techniques.\n",
    "\n",
    "Changing Patterns and Dynamics: Time series data can exhibit changes in patterns, trends, or seasonality over time. Forecasting models might struggle to adapt to these changing dynamics, leading to less accurate predictions. Continuous monitoring and model retraining are essential to address this limitation.\n",
    "\n",
    "Uncertainty and Error Propagation: Forecasting inherently involves uncertainty, and prediction errors can propagate over time. As the forecasting horizon increases, the confidence intervals widen, making long-term predictions less reliable. Proper interpretation and communication of forecast uncertainties are crucial for decision-making.\n",
    "\n",
    "Complex Relationships and External Factors: Time series data can be influenced by various external factors that are not explicitly captured in the dataset. For example, economic indicators, weather conditions, or social events can impact sales or demand patterns. Incorporating these external factors into forecasting models can be challenging but essential for accurate predictions.\n",
    "\n",
    "Data Stationarity: Many forecasting models assume stationarity, which implies that the statistical properties of the data remain constant over time. However, real-world time series often exhibit non-stationarity, requiring transformations or differencing to make them stationary and suitable for modeling.\n",
    "\n",
    "Overfitting and Model Selection: Selecting an appropriate forecasting model and avoiding overfitting can be challenging. It involves striking a balance between model complexity and generalizability. Choosing the right model architecture, incorporating relevant features, and using appropriate evaluation metrics are crucial for accurate forecasting.\n",
    "\n",
    "Addressing these challenges requires a combination of statistical techniques, domain expertise, and continuous evaluation and refinement of forecasting models. It's important to understand the limitations and uncertainties associated with time series forecasting and use it as one of the tools for informed decision-making rather than relying solely on predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ffd99-bb6c-46bc-afcb-4baa01135ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q5.\n",
    "\n",
    "ARIMA (AutoRegressive Integrated Moving Average) modeling is a popular and powerful time series forecasting technique. It combines autoregressive (AR), differencing (I), and moving average (MA) components to capture the patterns and dependencies in time series data. ARIMA models are widely used due to their flexibility and ability to handle a wide range of time series patterns.\n",
    "\n",
    "The AR component represents the linear regression of the variable against its own lagged values. It captures the dependency of the current value on its previous values. The MA component represents the linear regression of the variable against the error terms of its lagged values. It captures the dependency on past forecast errors. The I component represents differencing, which helps in making the data stationary by removing trends or seasonality.\n",
    "\n",
    "The ARIMA(p, d, q) model is specified by three parameters:\n",
    "\n",
    "p (AR Order): It represents the number of lagged observations included in the autoregressive component. A higher value of p indicates a more complex dependency on past values.\n",
    "\n",
    "d (Differencing Order): It represents the number of times differencing is applied to make the data stationary. Differencing helps in removing trends or seasonality present in the data.\n",
    "\n",
    "q (MA Order): It represents the number of lagged forecast errors included in the moving average component. A higher value of q indicates a more complex dependency on past errors.\n",
    "\n",
    "The ARIMA modeling process involves the following steps:\n",
    "\n",
    "Data Preprocessing: The time series data is preprocessed to handle missing values, outliers, and ensure stationarity if required. This may involve differencing the data to remove trends or seasonality.\n",
    "\n",
    "Model Identification: The appropriate values for p, d, and q are determined by analyzing the autocorrelation and partial autocorrelation plots of the differenced data. These plots help identify the significant lags and dependencies.\n",
    "\n",
    "Model Estimation: The ARIMA model is estimated using maximum likelihood estimation or least squares estimation. The model parameters are estimated based on the observed data and the selected values of p, d, and q.\n",
    "\n",
    "Model Diagnostic Checking: The fitted model is evaluated by analyzing the residuals to ensure that they are white noise. Residual analysis involves examining the autocorrelation of residuals, checking for normality, and detecting any remaining patterns or outliers.\n",
    "\n",
    "Forecasting: Once the model is deemed satisfactory, it can be used to generate forecasts for future time points. The forecasts are based on the estimated model parameters and the observed data.\n",
    "\n",
    "ARIMA models can be extended to include additional components such as seasonal ARIMA (SARIMA) for handling seasonal patterns or external regressors (ARIMAX) to incorporate the influence of external variables on the time series.\n",
    "\n",
    "ARIMA modeling is widely implemented in various software packages and programming languages. It provides a flexible and widely applicable approach for time series forecasting, making it a valuable tool for business planning, decision-making, and understanding the future behavior of time-dependent data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e14137-3eed-4487-96de-f0cfd2656d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q6.\n",
    "\n",
    "Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots are useful tools in identifying the order of the autoregressive (AR) and moving average (MA) components of an ARIMA model. These plots provide insights into the correlation structure of the time series data.\n",
    "\n",
    "The Autocorrelation Function (ACF) measures the correlation between the time series and its lagged values. It plots the correlation coefficient on the y-axis against the lag on the x-axis. ACF helps in identifying the order of the Moving Average (MA) component in the ARIMA model.\n",
    "\n",
    "The Partial Autocorrelation Function (PACF) measures the correlation between the time series and its lagged values while removing the influence of intermediate lags. It plots the partial correlation coefficient on the y-axis against the lag on the x-axis. PACF helps in identifying the order of the Autoregressive (AR) component in the ARIMA model.\n",
    "\n",
    "Interpreting ACF and PACF plots can help determine the appropriate values for p (AR order) and q (MA order) in an ARIMA model. Here are some general guidelines:\n",
    "\n",
    "Identifying AR Component (p):\n",
    "In the PACF plot, significant spikes at specific lags indicate direct correlation with those lags. Lagged values beyond the significant spikes generally have partial correlation close to zero. The lag corresponding to the last significant spike in the PACF plot suggests the order of the AR component (p) in the ARIMA model.\n",
    "Identifying MA Component (q):\n",
    "In the ACF plot, significant spikes at specific lags indicate correlation with those lags. Lagged values beyond the significant spikes generally have autocorrelation close to zero. The lag corresponding to the last significant spike in the ACF plot suggests the order of the MA component (q) in the ARIMA model.\n",
    "Distinguishing AR and MA Components:\n",
    "ACF and PACF plots together can help distinguish between the AR and MA components. If the ACF plot has a significant spike at the first lag and the PACF plot decays exponentially, it suggests a first-order autoregressive (AR(1)) component. Conversely, if the PACF plot has a significant spike at the first lag and the ACF plot decays exponentially, it suggests a first-order moving average (MA(1)) component.\n",
    "It's important to note that interpreting ACF and PACF plots can be subjective, and there might be some ambiguity, especially when there are overlapping spikes or gradual decays. In such cases, comparing different plausible model orders, evaluating model diagnostics, and using information criteria (such as AIC or BIC) can aid in selecting the best-fitting ARIMA model.\n",
    "\n",
    "Overall, ACF and PACF plots serve as visual tools to identify the potential order of the AR and MA components in an ARIMA model, providing valuable guidance for the modeling process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026b25a-9085-463d-b6e8-f84da1f29913",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q7.\n",
    "\n",
    "\n",
    "ARIMA (AutoRegressive Integrated Moving Average) models make certain assumptions about the underlying time series data. These assumptions are important for model estimation, parameter interpretation, and ensuring the validity of model outputs. Here are the key assumptions of ARIMA models:\n",
    "\n",
    "Stationarity: ARIMA models assume that the time series is stationary, which means that the statistical properties of the data do not change over time. Stationarity is crucial for accurate model estimation. If the data is non-stationary, differencing can be applied to make it stationary before fitting the ARIMA model.\n",
    "\n",
    "Linearity: ARIMA models assume a linear relationship between the time series and its lagged values. This assumption implies that the relationships captured by the autoregressive (AR) and moving average (MA) components are linear.\n",
    "\n",
    "Independence: ARIMA models assume that the observations in the time series are independent of each other. In other words, there should not be any autocorrelation or dependence between consecutive observations.\n",
    "\n",
    "Testing these assumptions is an important step in ARIMA modeling. Here are some common techniques to test the assumptions:\n",
    "\n",
    "Stationarity Testing: Statistical tests can be performed to check for stationarity, such as the Augmented Dickey-Fuller (ADF) test or the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test. These tests evaluate whether the time series exhibits a unit root (indicating non-stationarity) or is stationary.\n",
    "\n",
    "Residual Analysis: After fitting an ARIMA model, the residuals (the differences between the observed values and the model predictions) should be examined. Residual analysis can help assess the assumptions of independence and linearity. The residuals should ideally exhibit no significant autocorrelation and should appear as white noise (random fluctuations).\n",
    "\n",
    "Normality Testing: Normality of the residuals can be tested using statistical tests such as the Shapiro-Wilk test, Anderson-Darling test, or visual inspection of a Q-Q plot. Deviations from normality may indicate violations of the linearity assumption or the presence of outliers or other non-linear patterns.\n",
    "\n",
    "Additionally, visual inspection of the time series plot, ACF, and PACF plots can provide insights into the behavior of the data and potential violations of the assumptions. If violations are detected, further data transformation, model specification changes, or consideration of alternative models may be necessary.\n",
    "\n",
    "It's important to note that while testing assumptions is valuable, some violations can be tolerated to a certain extent, depending on the specific context and objectives of the analysis. It is crucial to interpret the results of assumption testing in conjunction with other diagnostic checks and consider the impact on the reliability and interpretability of the model outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b87b2c-27fd-4ea9-a795-a1da8c1b0d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q8.\n",
    "\n",
    "When it comes to forecasting future sales based on monthly data for a retail store, a common approach is to use a type of time series model called Seasonal ARIMA (AutoRegressive Integrated Moving Average). Here's why Seasonal ARIMA is often a suitable choice:\n",
    "\n",
    "Capturing seasonality: Seasonal ARIMA models are designed to capture the recurring patterns or seasonality in the data, which is often observed in retail sales. Monthly sales data for a retail store typically exhibit seasonal fluctuations, such as higher sales during holiday seasons or certain months of the year. Seasonal ARIMA models can effectively model and forecast these patterns.\n",
    "\n",
    "Handling trends and stationarity: ARIMA models incorporate autoregressive (AR) and moving average (MA) components to capture trends and dependencies in the data. They can handle both short-term and long-term trends that may affect sales. Additionally, the integrated (I) component allows for differencing to make the time series stationary, which is a common requirement for many time series models.\n",
    "\n",
    "Flexibility in modeling: Seasonal ARIMA models offer flexibility by incorporating both non-seasonal and seasonal components. They can capture the overall trend, seasonality, and random variations in the data, allowing for accurate and reliable sales forecasts.\n",
    "\n",
    "Historical data utilization: Seasonal ARIMA models utilize historical sales data effectively. By considering the patterns and dependencies in the past three years of monthly sales data, the model can make informed predictions for future sales based on the historical patterns observed.\n",
    "\n",
    "Availability of software and resources: Seasonal ARIMA models are widely supported in various statistical software packages and libraries. This availability makes it easier to implement and apply these models to your retail sales forecasting problem. Additionally, there are ample resources and documentation available to guide you through the modeling process and parameter selection.\n",
    "\n",
    "It's worth mentioning that the suitability of a specific model ultimately depends on the characteristics of your sales data, such as the presence of multiple seasonalities, other external factors impacting sales, or specific patterns unique to your retail store. Therefore, it is recommended to analyze and explore the data thoroughly before selecting and fitting any particular model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f0fe1-59e8-4cb2-9e87-0c64f5aece82",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q9.\n",
    "\n",
    "Time series analysis is a powerful tool for understanding and forecasting data that evolves over time. However, it also has certain limitations. Here are some common limitations of time series analysis:\n",
    "\n",
    "Assumption of stationarity: Many time series models, such as ARIMA, assume that the underlying data is stationary, meaning that the statistical properties of the data do not change over time. However, real-world data often exhibit trends, seasonality, or other forms of non-stationarity, which can violate this assumption. In such cases, additional preprocessing steps or more advanced models may be required to handle non-stationary data.\n",
    "\n",
    "Limited incorporation of external factors: Traditional time series models typically focus on analyzing and forecasting based solely on past values of the time series itself. They may not consider or incorporate external factors or predictors that can influence the time series, such as economic indicators, weather conditions, or marketing campaigns. Neglecting these external factors may limit the accuracy and reliability of the forecasts, especially in scenarios where external factors have a significant impact on the time series.\n",
    "\n",
    "Difficulty in modeling complex patterns: Time series models may struggle to capture and represent complex patterns and dependencies in the data. For instance, if there are non-linear relationships or interactions between variables, traditional linear models like ARIMA may not adequately capture these complexities. In such cases, more advanced techniques, such as machine learning algorithms (e.g., recurrent neural networks), may be required.\n",
    "\n",
    "Limited performance with sparse or irregular data: Time series analysis assumes a regular and consistent time interval between data points. However, in some scenarios, data may be sparse or irregularly sampled. This can pose challenges for traditional time series models, which may require interpolation or resampling techniques to handle such data.\n",
    "\n",
    "Uncertainty in long-term forecasts: Time series models are generally better at short-term forecasting than long-term forecasting. As the forecast horizon increases, the uncertainty of predictions tends to grow, making it more challenging to accurately predict distant future values. This limitation is particularly relevant when trying to forecast events or trends that are far into the future.\n",
    "\n",
    "An example scenario where the limitations of time series analysis may be relevant is predicting stock market prices. Stock market data often exhibit non-stationarity, with trends, seasonality, and external factors (e.g., economic indicators, news events) playing crucial roles in price movements. Traditional time series models may struggle to capture and incorporate all these factors, resulting in suboptimal forecasts. To address these limitations, more sophisticated models that consider external factors, non-linear relationships, and high-frequency data may be necessary to improve the accuracy of stock market predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf607255-332c-472f-87f1-fd367b8b6edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q10.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
